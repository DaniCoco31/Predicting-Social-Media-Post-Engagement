{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will focus on hyperparameter tuning for the best-performing models from the previous notebook. We will use Grid Search to find the optimal parameters and evaluate the tuned models on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Preprocessed Data\n",
    "We begin by loading the preprocessed data once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.read_csv('../Data/Clean-Data/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('../Data/Clean-Data/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('../Data/Clean-Data/y_train.csv')\n",
    "y_test = pd.read_csv('../Data/Clean-Data/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert target to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data: The preprocessed data is reloaded for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Hyperparameter Tuning for XGBoost\n",
    "We will perform Grid Search to find the best parameters for the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best Score (Negative MSE): -1468.939231218048\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50],# 100, 200, 500],\n",
    "    'max_depth': [3],# 5, 7, 10],\n",
    "    'learning_rate': [0.2]# , 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Initialize Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring=scoring, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score (Negative MSE):\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search: We use Grid Search to explore different hyperparameter combinations and find the best configuration for the XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the Tuned XGBoost Model\n",
    "After tuning, we evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance with Best Parameters:\n",
      "Mean Absolute Error (MAE): 29.637879615610892\n",
      "Mean Squared Error (MSE): 1638.6236042712737\n",
      "R-squared: 0.3351529836654663\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "print(\"XGBoost Model Performance with Best Parameters:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_xgb}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_xgb}\")\n",
    "print(f\"R-squared: {r2_xgb}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: The tuned model is evaluated on the test set to compare its performance with the untuned version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hyperparameter Tuning for Random Forest\n",
    "Similarly, we perform hyperparameter tuning for the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters for Random Forest: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Score (Negative MSE): -1545.43907743731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50], #100, 200, 500, 1000],\n",
    "    'max_depth': [5], #10, 15, 20],\n",
    "    'min_samples_split': [2]#, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with Cross-Validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring=scoring, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_score_rf = grid_search_rf.best_score_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Best Parameters for Random Forest:\", best_params_rf)\n",
    "print(\"Best Score (Negative MSE):\", best_score_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search for Random Forest: Similar to XGBoost, we tune the Random Forest model using Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Tuned Random Forest Model\n",
    "Finally, we evaluate the tuned Random Forest model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance with Best Parameters:\n",
      "Mean Absolute Error (MAE): 29.617878327337333\n",
      "Mean Squared Error (MSE): 1629.475794837296\n",
      "R-squared: 0.33886464982436715\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Model Performance with Best Parameters:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'neurons_layer1': 64, 'neurons_layer2': 32, 'neurons_layer3': 16, 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danicoco/Escritorio/IronHack-DataAnalysis/8. week-eight/project/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training with parameters: {'neurons_layer1': 128, 'neurons_layer2': 64, 'neurons_layer3': 32, 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danicoco/Escritorio/IronHack-DataAnalysis/8. week-eight/project/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training with parameters: {'neurons_layer1': 32, 'neurons_layer2': 16, 'neurons_layer3': 8, 'dropout_rate': 0.1, 'batch_size': 16, 'epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danicoco/Escritorio/IronHack-DataAnalysis/8. week-eight/project/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Best parameters: {'neurons_layer1': 64, 'neurons_layer2': 32, 'neurons_layer3': 16, 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 100}\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "TensorFlow Model Performance with Best Parameters:\n",
      "Mean Absolute Error (MAE): 30.63292102077948\n",
      "Mean Squared Error (MSE): 1712.349695024922\n",
      "R-squared: 0.305239737033844\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model(input_dim, neurons_layer1=64, neurons_layer2=32, neurons_layer3=16, dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        Dense(neurons_layer1, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(neurons_layer2, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(neurons_layer3, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter combinations to try\n",
    "param_combinations = [\n",
    "    {'neurons_layer1': 64, 'neurons_layer2': 32, 'neurons_layer3': 16, 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 100},\n",
    "    {'neurons_layer1': 128, 'neurons_layer2': 64, 'neurons_layer3': 32, 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 150},\n",
    "    {'neurons_layer1': 32, 'neurons_layer2': 16, 'neurons_layer3': 8, 'dropout_rate': 0.1, 'batch_size': 16, 'epochs': 50}\n",
    "]\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, mse, r2\n",
    "\n",
    "# Prepare data (assuming X_train_scaled, y_train, X_test_scaled, y_test are already defined)\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Manually search through hyperparameters\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model(input_dim, **{k: v for k, v in params.items() if k != 'batch_size' and k != 'epochs'})\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae_tf, mse_tf, r2_tf = evaluate_model(model, X_test_scaled, y_test)\n",
    "     \n",
    "    # Check if this is the best model so far\n",
    "    if mse_tf < best_mse:\n",
    "        best_mse = mse_tf\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "mae_tf, mse_tf, r2_tf = evaluate_model(best_model, X_test_scaled, y_test)\n",
    "\n",
    "print(\"TensorFlow Model Performance with Best Parameters:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_tf}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_tf}\")\n",
    "print(f\"R-squared: {r2_tf}\")\n",
    "\n",
    "\n",
    "# Assuming best_model is the best TensorFlow model after manual tuning\n",
    "best_tf_model = best_model  # Assign best_model to best_tf_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: The tuned Random Forest model is evaluated to determine if the tuning improved its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model 4 - XGBoost\n",
    "We will now test the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.01, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Score (Negative MSE): -1980.6512935756223\n",
      "Gradient Boosting Model Performance with Best Parameters:\n",
      "Mean Absolute Error (MAE): 34.5589328275395\n",
      "Mean Squared Error (MSE): 1955.156942012443\n",
      "R-squared: 0.2067244118622915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "## Step 4: Hyperparameter Tuning for Gradient Boosting\n",
    "# Here, we perform hyperparameter tuning for the Gradient Boosting model using Grid Search with Cross-Validation.\n",
    "\n",
    "# Initialize the Gradient Boosting model without setting specific hyperparameters\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50],# 100, 200],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.01],# 0.1, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'min_samples_split': [2],#, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1]#, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with Cross-Validation\n",
    "grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_gb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params_gb = grid_search_gb.best_params_\n",
    "best_score_gb = grid_search_gb.best_score_\n",
    "\n",
    "print(\"Best Parameters for Gradient Boosting:\", best_params_gb)\n",
    "print(\"Best Score (Negative MSE):\", best_score_gb)\n",
    "\n",
    "## Step 5: Evaluate the Tuned Gradient Boosting Model\n",
    "# After tuning, we evaluate the performance of the best Gradient Boosting model on the test set.\n",
    "\n",
    "# Retrieve the best Gradient Boosting model\n",
    "best_gb_model = grid_search_gb.best_estimator_\n",
    "\n",
    "# Train the Gradient Boosting model with the best parameters on the entire training data\n",
    "best_gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_gb = best_gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print regression metrics\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Model Performance with Best Parameters:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_gb}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_gb}\")\n",
    "print(f\"R-squared: {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Comparison of models\n",
    "Compare all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "Mean Absolute Error (MAE): 29.617878327337333\n",
      "Mean Squared Error (MSE): 1629.475794837296\n",
      "R-squared: 0.33886464982436715\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Mean Absolute Error (MAE): 34.5589328275395\n",
      "Mean Squared Error (MSE): 1955.156942012443\n",
      "R-squared: 0.2067244118622915\n",
      "\n",
      "TensorFlow Neural Network Performance:\n",
      "Mean Absolute Error (MAE): 30.63292102077948\n",
      "Mean Squared Error (MSE): 1712.349695024922\n",
      "R-squared: 0.305239737033844\n",
      "\n",
      "XGBoost Performance:\n",
      "Mean Absolute Error (MAE): 29.637879615610892\n",
      "Mean Squared Error (MSE): 1638.6236042712737\n",
      "R-squared: 0.3351529836654663\n",
      "\n",
      "The best model is: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've completed training and evaluating all models, including the TensorFlow model\n",
    "# Now assign best_model to best_tf_model\n",
    "best_tf_model = best_model\n",
    "\n",
    "## Step 6: Model Comparison\n",
    "# Compare the performance of all the models and select the best one.\n",
    "\n",
    "# Store the performance metrics for each model in a dictionary\n",
    "model_performance = {\n",
    "    'Random Forest': {\n",
    "        'MAE': mae_rf,\n",
    "        'MSE': mse_rf,\n",
    "        'R2': r2_rf,\n",
    "        'Model': best_rf_model  # Ensure best_rf_model is defined\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'MAE': mae_gb,\n",
    "        'MSE': mse_gb,\n",
    "        'R2': r2_gb,\n",
    "        'Model': best_gb_model  # Ensure best_gb_model is defined\n",
    "    },\n",
    "    'TensorFlow Neural Network': {\n",
    "        'MAE': mae_tf,\n",
    "        'MSE': mse_tf,\n",
    "        'R2': r2_tf,\n",
    "        'Model': best_tf_model  # Now correctly assigned\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'MAE': mae_xgb,\n",
    "        'MSE': mse_xgb,\n",
    "        'R2': r2_xgb,\n",
    "        'Model': xgb_model  # Ensure xgb_model is defined\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print the performance of each model\n",
    "for model_name, metrics in model_performance.items():\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {metrics['MAE']}\")\n",
    "    print(f\"Mean Squared Error (MSE): {metrics['MSE']}\")\n",
    "    print(f\"R-squared: {metrics['R2']}\")\n",
    "    print()\n",
    "\n",
    "# Determine the best model based on R-squared or MSE\n",
    "best_model_name = max(model_performance, key=lambda name: model_performance[name]['R2'])\n",
    "best_final_model = model_performance[best_model_name]['Model']\n",
    "\n",
    "print(f\"The best model is: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save the Model and Scaler\n",
    "Save the best model to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features saved successfully!\n",
      "Scaler saved successfully!\n",
      "Best model (Random Forest) saved as 'best_model.pkl'\n",
      "Model loaded successfully for verification!\n"
     ]
    }
   ],
   "source": [
    "## Step 7: Save the Model and Scaler\n",
    "# Save the best model and the scaler for future use.\n",
    "\n",
    "# Concatenate the features (X) data\n",
    "X_combined = pd.concat([X_train_scaled, X_test_scaled], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Save the combined features\n",
    "X_combined.to_csv('../Data/Clean-Data/X_combined.csv', index=False)\n",
    "print(\"Combined features saved successfully!\")\n",
    "\n",
    "# Initialize and fit the scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_combined)\n",
    "scaled_features = scaler.fit_transform(X_combined)\n",
    "scaler.transform(X_combined)\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print(\"Scaler saved successfully!\")\n",
    "\n",
    "# Save the best model\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_final_model, file)\n",
    "print(f\"Best model ({best_model_name}) saved as 'best_model.pkl'\")\n",
    "\n",
    "# Verify that the model can be loaded\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully for verification!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we successfully performed hyperparameter tuning for two of our best models and evaluated their performance on the test set. The results of this tuning will help us choose the final model for predicting Instagram post interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
