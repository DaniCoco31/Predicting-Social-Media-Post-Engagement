{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will focus on loading the initial dataset and the embedded data. The primary goal is to combine these datasets, ensuring that only the rows present in both data frames based on the 'id' and 'description' columns are retained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Import Necessary Libraries\n",
    "We start by importing the necessary libraries for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Data Loaded:\n",
      "     id                                        description  interactions  \\\n",
      "0  7583  matt dean dd with the three bears nwent to vis...            29   \n",
      "1    80  sunday night with z meangirls sunday girlsnigh...            24   \n",
      "\n",
      "  day_of_week    time_of_day  following  followers  num_posts  \\\n",
      "0      Sunday      afternoon       1777        449        808   \n",
      "1      Monday  early_morning        976        843       2376   \n",
      "\n",
      "   is_business_account              category  \n",
      "0                False                family  \n",
      "1                False  diaries_&_daily_life  \n",
      "Shape of the base data: (1000000, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/DF_complete/base.csv')\n",
    "print(\"Base Data Loaded:\")\n",
    "print(data.head(2))\n",
    "print(\"Shape of the base data:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the embedded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11093/436165670.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                        description  embedded_0  \\\n",
      "0      3701655  cantinhodosmanos dollishill portugueserestaura...   -0.586680   \n",
      "1       404256                                  my kind of curves   -0.028337   \n",
      "2      4761324  severe thunderstorm along with flooding alert ...   -0.414129   \n",
      "3      1905033  i think this is what dreams are made of not su...   -0.305486   \n",
      "4      2801775  the porsche gb gt clubsport the track only ver...   -0.160066   \n",
      "...        ...                                                ...         ...   \n",
      "99995  3022302                    my kinda clich n goalsofdancing   -0.320121   \n",
      "99996  3001817  don t drag me down one of my favorite sxdx son...    0.144971   \n",
      "99997  2879561  only a couple days left before kicking the roo...    0.175868   \n",
      "99998  2888955             rip soda peezy te i luv my real niggas    1.184273   \n",
      "99999  3513332                posted on the block like a low life    0.015594   \n",
      "\n",
      "       embedded_1  embedded_2  embedded_3  embedded_4  embedded_5  embedded_6  \\\n",
      "0       -0.448536   -0.334474   -0.060851   -0.776139   -0.470470   -0.105071   \n",
      "1       -0.245603   -0.220984    0.007035   -0.447282   -0.136009    0.421169   \n",
      "2        0.695709    0.128879   -0.110286   -0.487140   -0.245850    0.207405   \n",
      "3       -0.059497   -0.064720   -0.191380   -0.467013   -1.066474    0.364329   \n",
      "4        0.461084    0.193205    0.412882   -0.162142    0.226710    0.304265   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "99995   -0.053500   -0.279955   -0.145206   -0.338230   -0.654640    0.040666   \n",
      "99996   -0.007925   -0.120730    0.907274    0.520030   -0.587996   -0.089171   \n",
      "99997   -0.126542   -0.162367    0.452478    0.087191   -0.542720    0.835744   \n",
      "99998    0.051423    0.277732    0.738912   -0.255837   -1.174019    0.802750   \n",
      "99999   -0.389104   -0.083347    0.561219   -0.399727   -0.573095    0.692291   \n",
      "\n",
      "       embedded_7  ...  embedded_1014  embedded_1015  embedded_1016  \\\n",
      "0        0.291425  ...       0.400686       0.107695       0.314953   \n",
      "1        0.365494  ...       0.894649      -0.412131      -0.125622   \n",
      "2        0.402580  ...       0.332524      -0.208268       0.161450   \n",
      "3        0.816441  ...      -0.046834      -0.714047       0.341694   \n",
      "4       -0.169321  ...       0.158257      -0.305152       0.053200   \n",
      "...           ...  ...            ...            ...            ...   \n",
      "99995    0.457381  ...       0.523542      -0.790104       0.631993   \n",
      "99996    0.252892  ...       1.046966      -0.003961       0.116896   \n",
      "99997    0.443105  ...      -0.177720      -0.194140      -0.228065   \n",
      "99998    0.192421  ...       0.882543      -0.067086      -0.131076   \n",
      "99999    0.170820  ...       0.328142      -0.087985      -0.259500   \n",
      "\n",
      "       embedded_1017  embedded_1018  embedded_1019  embedded_1020  \\\n",
      "0          -0.375157      -0.015337       0.512360       0.331204   \n",
      "1          -0.323468       0.229343      -0.005884       0.411874   \n",
      "2          -0.326083       0.850944       0.824841       0.892783   \n",
      "3          -0.323714       1.005489       0.096725       0.012306   \n",
      "4           0.115153       0.452684       0.086269       0.354458   \n",
      "...              ...            ...            ...            ...   \n",
      "99995      -0.584517       0.590119       0.352175       0.446120   \n",
      "99996      -0.128246       0.758916       0.973736       0.884892   \n",
      "99997       0.130062       0.678958       1.449481       0.059523   \n",
      "99998       0.437233       0.252121       1.794766      -0.758586   \n",
      "99999      -0.381995       0.674992       0.848286      -0.077535   \n",
      "\n",
      "       embedded_1021  embedded_1022  embedded_1023  \n",
      "0          -0.207912      -0.496190       0.229807  \n",
      "1          -0.198382       0.759338      -0.637053  \n",
      "2           0.026135      -0.104516       0.348993  \n",
      "3          -0.012197       0.669394      -0.229690  \n",
      "4          -0.375255      -0.081530      -0.534565  \n",
      "...              ...            ...            ...  \n",
      "99995      -0.149827       0.023068      -0.660284  \n",
      "99996      -0.411045      -0.260686      -0.962527  \n",
      "99997      -0.504055      -0.956185      -0.514953  \n",
      "99998      -0.601015       0.273328      -0.431224  \n",
      "99999      -0.355943       0.437937      -0.021207  \n",
      "\n",
      "[100000 rows x 1026 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of file paths\n",
    "file_paths = [#'../Data/DF_embedded/df_1-embed.csv', \n",
    "              #'../Data/DF_embedded/df_2-embed.csv', \n",
    "              #'../Data/DF_embedded/df_3-embed.csv',\n",
    "              #'../Data/DF_embedded/df_4-embed.csv',\n",
    "              #'../Data/DF_embedded/df_5-embed.csv',\n",
    "              '../Data/DF_embedded/df_6-embed.csv',\n",
    "              #'../Data/DF_embedded/df_7-embed.csv',\n",
    "              #'../Data/DF_embedded/df_8-embed.csv',\n",
    "              #'../Data/DF_embedded/df_9-embed.csv',\n",
    "              #'../Data/DF_embedded/df_10-embed.csv'\n",
    "              ]\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "for file in file_paths:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Drop the first row\n",
    "    df = df.drop(df.index[0])\n",
    "    \n",
    "    # Append the modified dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "embed_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the concatenated dataframe\n",
    "print(embed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading: We load two datasets â€“ the original base.csv and the embedded data df_2-embed.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Merging Datasets\n",
    "We combine the base data and the embedded data, keeping only the rows that are present in both dataframes based on the 'id' and 'description' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the datasets on 'id' and 'description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data:\n",
      "     id                                        description  interactions  \\\n",
      "0   778                       special friends yoshi mylove            13   \n",
      "1  1407  i brushed a totino s pizza with garlic butter ...           205   \n",
      "\n",
      "  day_of_week    time_of_day  following  followers  num_posts  \\\n",
      "0   Wednesday  early_morning        737       4694       1512   \n",
      "1      Sunday  early_morning       1269       3426       4487   \n",
      "\n",
      "   is_business_account       category  ...  embedded_1014  embedded_1015  \\\n",
      "0                False  relationships  ...       1.020114       0.405854   \n",
      "1                False  food_&_dining  ...       0.686622      -0.422867   \n",
      "\n",
      "   embedded_1016  embedded_1017  embedded_1018  embedded_1019  embedded_1020  \\\n",
      "0      -0.018507       0.441405       0.582225       0.617475      -0.021549   \n",
      "1       0.089943      -1.160441       0.821644      -0.089272      -0.320949   \n",
      "\n",
      "   embedded_1021  embedded_1022  embedded_1023  \n",
      "0      -0.832010      -0.189848      -0.059992  \n",
      "1      -0.425352       0.193892      -0.109802  \n",
      "\n",
      "[2 rows x 1034 columns]\n",
      "Shape of the merged data: (99489, 1034)\n"
     ]
    }
   ],
   "source": [
    "df = data.merge(embed_df, on=['id', 'description'])\n",
    "print(\"Merged Data:\")\n",
    "print(df.head(2))\n",
    "print(\"Shape of the merged data:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the merged data for the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Data/Clean-Data/merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1034)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging: The merge function combines the two datasets on the common columns, ensuring only matching rows are retained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The merged dataset is saved as merged_data.csv for further processing in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
